"""
ReliefLink AI Service
Python microservice ƒë·ªÉ d·ª± b√°o nhu c·∫ßu c·ª©u tr·ª£ d·ª±a tr√™n historical data
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict
from datetime import datetime, timedelta
try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
    PSYCOPG_VERSION = 2
except ImportError:
    try:
        import psycopg
        from psycopg.rows import dict_row
        PSYCOPG_VERSION = 3
    except ImportError:
        raise ImportError("Please install psycopg2-binary or psycopg[binary]")
import os
from dotenv import load_dotenv
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
import joblib
import sys
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import requests

# Import weather service
try:
    from weather_service import check_weather_and_predict, get_province_coords
except ImportError:
    print("‚ö†Ô∏è  weather_service module not found, weather features disabled")
    check_weather_and_predict = None
    get_province_coords = None

load_dotenv()

app = FastAPI(title="ReliefLink AI Service", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Trong production n√™n ch·ªâ ƒë·ªãnh c·ª• th·ªÉ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database connection
DATABASE_URL = os.getenv("DATABASE_URL")

# Model paths
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# Next.js API URL for sending notifications
NEXTJS_API_URL = os.getenv("NEXTJS_API_URL", "http://localhost:3000")

# Scheduler for periodic weather checks
scheduler = BackgroundScheduler()
scheduler.start()


class PredictionRequest(BaseModel):
    tinh_thanh: str
    loai_thien_tai: Optional[str] = None
    so_nguoi: Optional[int] = None


class PredictionResponse(BaseModel):
    tinh_thanh: str
    loai_thien_tai: str
    du_doan_nhu_cau_thuc_pham: int
    du_doan_nhu_cau_nuoc: int
    du_doan_nhu_cau_thuoc: int
    du_doan_nhu_cau_cho_o: int
    ngay_du_bao: str
    confidence_score: Optional[float] = None
    method: str = "heuristic"  # heuristic, ml, hybrid


class WeatherAlertRequest(BaseModel):
    tinh_thanh: str
    message: Optional[str] = None


def get_db_connection():
    """T·∫°o k·∫øt n·ªëi database"""
    try:
        if PSYCOPG_VERSION == 3:
            conn = psycopg.connect(DATABASE_URL)
            return conn
        else:
            conn = psycopg2.connect(DATABASE_URL)
            return conn
    except Exception as e:
        print(f"Database connection error: {e}")
        return None


def analyze_historical_data(tinh_thanh: str, loai_thien_tai: Optional[str] = None):
    """
    Ph√¢n t√≠ch d·ªØ li·ªáu l·ªãch s·ª≠ t·ª´ database ƒë·ªÉ t·∫°o d·ª± b√°o
    """
    conn = get_db_connection()
    if not conn:
        return None

    try:
        if PSYCOPG_VERSION == 3:
            cursor = conn.cursor(row_factory=dict_row)
        else:
            cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # Query historical requests
        query = """
            SELECT 
                loai_yeu_cau,
                so_nguoi,
                do_uu_tien,
                created_at,
                CASE 
                    WHEN dia_chi LIKE %s THEN true
                    ELSE false
                END as in_province
            FROM yeu_cau_cuu_tros
            WHERE created_at >= NOW() - INTERVAL '6 months'
            ORDER BY created_at DESC
            LIMIT 500
        """
        
        cursor.execute(query, (f'%{tinh_thanh}%',))
        historical_requests = cursor.fetchall()
        
        # Query historical distributions ƒë·ªÉ t√≠nh actual needs
        dist_query = """
            SELECT 
                ph.id_yeu_cau,
                yc.so_nguoi,
                nr.loai,
                ph.thoi_gian_xuat,
                ph.thoi_gian_giao
            FROM phan_phois ph
            JOIN yeu_cau_cuu_tros yc ON ph.id_yeu_cau = yc.id
            JOIN nguon_lucs nr ON ph.id_nguon_luc = nr.id
            WHERE ph.trang_thai = 'hoan_thanh'
            AND ph.thoi_gian_xuat >= NOW() - INTERVAL '6 months'
            LIMIT 200
        """
        
        cursor.execute(dist_query)
        historical_distributions = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        return {
            "requests": historical_requests,
            "distributions": historical_distributions
        }
    except Exception as e:
        print(f"Error analyzing historical data: {e}")
        if conn:
            conn.close()
        return None


def send_alert_to_nextjs(tinh_thanh: str, disaster_types: List[str], risk_level: str, details: Dict):
    """
    G·ª≠i c·∫£nh b√°o ƒë·∫øn Next.js API ƒë·ªÉ t·∫°o notification
    """
    try:
        # Call Next.js API endpoint
        url = f"{NEXTJS_API_URL}/api/ai/weather-alert"
        
        payload = {
            "tinh_thanh": tinh_thanh,
            "disaster_types": disaster_types,
            "risk_level": risk_level,
            "details": details
        }
        
        response = requests.post(
            url,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"‚úÖ Alert sent successfully: {result.get('notifications_sent', 0)} notifications")
            return True
        else:
            print(f"‚ö†Ô∏è  Failed to send alert: {response.status_code} - {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå Error sending alert to Next.js: {e}")
        return False


def heuristic_prediction(
    tinh_thanh: str, 
    loai_thien_tai: Optional[str] = None,
    so_nguoi: Optional[int] = None
) -> PredictionResponse:
    """
    D·ª± b√°o d·ª±a tr√™n heuristic v√† historical patterns
    Kh√¥ng c·∫ßn train model, ch·∫°y real-time
    """
    historical_data = analyze_historical_data(tinh_thanh, loai_thien_tai)
    
    # Base multipliers theo lo·∫°i thi√™n tai
    disaster_multipliers = {
        "L≈© l·ª•t": {"food": 1.2, "water": 1.5, "medicine": 1.1, "shelter": 1.3},
        "B√£o": {"food": 1.5, "water": 1.3, "medicine": 1.2, "shelter": 1.6},
        "H·∫°n h√°n": {"food": 1.1, "water": 2.0, "medicine": 1.0, "shelter": 0.8},
        "S·∫°t l·ªü ƒë·∫•t": {"food": 1.3, "water": 1.2, "medicine": 1.4, "shelter": 1.8},
        "ƒê·ªông ƒë·∫•t": {"food": 1.4, "water": 1.4, "medicine": 1.5, "shelter": 2.0},
        "Ch√°y r·ª´ng": {"food": 1.2, "water": 1.6, "medicine": 1.3, "shelter": 1.4},
    }
    
    # Default multipliers
    multipliers = disaster_multipliers.get(
        loai_thien_tai or "L≈© l·ª•t",
        {"food": 1.2, "water": 1.3, "medicine": 1.1, "shelter": 1.2}
    )
    
    # Base needs per person (kg/day, l√≠t/day, etc.)
    base_food_per_person = 2.0  # kg/day
    base_water_per_person = 5.0  # l√≠t/day
    base_medicine_per_person = 0.5  # ƒë∆°n v·ªã/day
    base_shelter_per_household = 1  # h·ªô
    
    # Estimate affected people t·ª´ historical data
    if historical_data and historical_data.get("requests"):
        people_list = [r["so_nguoi"] for r in historical_data["requests"] if r.get("so_nguoi")]
        if people_list:
            avg_people = float(np.mean(people_list))
            people_estimate = int(avg_people * 1.1)  # +10% buffer
        else:
            people_estimate = so_nguoi or 100
    else:
        people_estimate = so_nguoi or 100
    
    # Estimate households (average 4 people per household in Vietnam)
    households = max(1, people_estimate // 4)
    
    # Calculate predictions for 7 days
    days = 7
    
    food_need = int(people_estimate * base_food_per_person * days * multipliers["food"])
    water_need = int(people_estimate * base_water_per_person * days * multipliers["water"])
    medicine_need = int(people_estimate * base_medicine_per_person * days * multipliers["medicine"])
    shelter_need = int(households * multipliers["shelter"])
    
    # Apply historical adjustment n·∫øu c√≥ data
    if historical_data and historical_data.get("distributions"):
        # Calculate average actual usage
        distributions = historical_data["distributions"]
        people_list = [d["so_nguoi"] for d in distributions if d.get("so_nguoi")]
        if people_list:
            avg_people_historical = float(np.mean(people_list))
            
            if avg_people_historical > 0:
                # Adjust based on historical patterns
                adjustment_factor = float(people_estimate) / avg_people_historical
                food_need = int(food_need * adjustment_factor)
                water_need = int(water_need * adjustment_factor)
                medicine_need = int(medicine_need * adjustment_factor)
    
    # Ensure minimum values
    food_need = max(1000, food_need)
    water_need = max(2000, water_need)
    medicine_need = max(500, medicine_need)
    shelter_need = max(50, shelter_need)
    
    return PredictionResponse(
        tinh_thanh=tinh_thanh,
        loai_thien_tai=loai_thien_tai or "L≈© l·ª•t",
        du_doan_nhu_cau_thuc_pham=food_need,
        du_doan_nhu_cau_nuoc=water_need,
        du_doan_nhu_cau_thuoc=medicine_need,
        du_doan_nhu_cau_cho_o=shelter_need,
        ngay_du_bao=(datetime.now() + timedelta(days=7)).isoformat(),
        confidence_score=0.75 if historical_data else 0.5,
        method="heuristic"
    )


def train_ml_model():
    """
    Train ML model t·ª´ historical data
    Ch·∫°y ƒë·ªãnh k·ª≥ (cron job) ho·∫∑c on-demand
    """
    historical_data = analyze_historical_data("")  # Get all data
    
    if not historical_data or not historical_data["distributions"]:
        print("Not enough data to train model")
        return False
    
    # Prepare features
    X = []
    y_food = []
    y_water = []
    y_medicine = []
    y_shelter = []
    
    distributions = historical_data["distributions"]
    
    for dist in distributions:
        # Features: s·ªë ng∆∞·ªùi, lo·∫°i thi√™n tai, th·ªùi gian, ...
        features = [
            dist["so_nguoi"],
            hash(dist.get("loai", "")) % 100,  # Simple encoding
        ]
        X.append(features)
        
        # Labels: actual distributed amounts (s·∫Ω c·∫ßn th√™m fields trong DB)
        # T·∫°m th·ªùi estimate t·ª´ so_nguoi
        y_food.append(dist["so_nguoi"] * 2 * 7)
        y_water.append(dist["so_nguoi"] * 5 * 7)
        y_medicine.append(dist["so_nguoi"] * 0.5 * 7)
        y_shelter.append(max(1, dist["so_nguoi"] // 4))
    
    if len(X) < 10:
        print("Not enough data for ML model")
        return False
    
    X = np.array(X)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Train models
    models = {
        "food": RandomForestRegressor(n_estimators=50, random_state=42),
        "water": RandomForestRegressor(n_estimators=50, random_state=42),
        "medicine": RandomForestRegressor(n_estimators=50, random_state=42),
        "shelter": RandomForestRegressor(n_estimators=50, random_state=42),
    }
    
    models["food"].fit(X_scaled, y_food)
    models["water"].fit(X_scaled, y_water)
    models["medicine"].fit(X_scaled, y_medicine)
    models["shelter"].fit(X_scaled, y_shelter)
    
    # Save models
    joblib.dump(scaler, f"{MODEL_DIR}/scaler.pkl")
    for name, model in models.items():
        joblib.dump(model, f"{MODEL_DIR}/model_{name}.pkl")
    
    print("Models trained and saved successfully")
    return True


def ml_prediction(tinh_thanh: str, so_nguoi: Optional[int] = None) -> Optional[PredictionResponse]:
    """
    D·ª± b√°o b·∫±ng ML model (n·∫øu ƒë√£ train)
    """
    model_paths = {
        "food": f"{MODEL_DIR}/model_food.pkl",
        "water": f"{MODEL_DIR}/model_water.pkl",
        "medicine": f"{MODEL_DIR}/model_medicine.pkl",
        "shelter": f"{MODEL_DIR}/model_shelter.pkl",
    }
    
    scaler_path = f"{MODEL_DIR}/scaler.pkl"
    
    # Check if models exist
    if not all(os.path.exists(path) for path in list(model_paths.values()) + [scaler_path]):
        return None
    
    try:
        scaler = joblib.load(scaler_path)
        models = {name: joblib.load(path) for name, path in model_paths.items()}
        
        # Prepare features
        features = np.array([[so_nguoi or 100, hash(tinh_thanh) % 100]])
        features_scaled = scaler.transform(features)
        
        # Predict
        food = int(models["food"].predict(features_scaled)[0])
        water = int(models["water"].predict(features_scaled)[0])
        medicine = int(models["medicine"].predict(features_scaled)[0])
        shelter = int(models["shelter"].predict(features_scaled)[0])
        
        return PredictionResponse(
            tinh_thanh=tinh_thanh,
            loai_thien_tai="D·ª± b√°o",
            du_doan_nhu_cau_thuc_pham=max(1000, food),
            du_doan_nhu_cau_nuoc=max(2000, water),
            du_doan_nhu_cau_thuoc=max(500, medicine),
            du_doan_nhu_cau_cho_o=max(50, shelter),
            ngay_du_bao=(datetime.now() + timedelta(days=7)).isoformat(),
            confidence_score=0.85,
            method="ml"
        )
    except Exception as e:
        print(f"ML prediction error: {e}")
        return None


@app.get("/")
def root():
    return {
        "service": "ReliefLink AI Service",
        "version": "1.0.0",
        "status": "running",
        "methods": ["heuristic", "ml", "hybrid"]
    }


@app.get("/health")
def health_check():
    conn = get_db_connection()
    db_status = "connected" if conn else "disconnected"
    if conn:
        conn.close()
    
    return {
        "status": "healthy",
        "database": db_status,
        "models_available": {
            "heuristic": True,
            "ml": all(os.path.exists(f"{MODEL_DIR}/model_{name}.pkl") 
                     for name in ["food", "water", "medicine", "shelter"])
        }
    }


@app.post("/predict", response_model=PredictionResponse)
def predict(request: PredictionRequest):
    """
    T·∫°o d·ª± b√°o nhu c·∫ßu c·ª©u tr·ª£
    """
    try:
        # Try ML first, fallback to heuristic
        ml_result = ml_prediction(request.tinh_thanh, request.so_nguoi)
        
        if ml_result:
            return ml_result
        
        # Use heuristic
        return heuristic_prediction(
            request.tinh_thanh,
            request.loai_thien_tai,
            request.so_nguoi
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict/batch", response_model=List[PredictionResponse])
def predict_batch(requests: List[PredictionRequest]):
    """
    T·∫°o nhi·ªÅu d·ª± b√°o c√πng l√∫c
    """
    results = []
    for req in requests:
        try:
            pred = predict(req)
            results.append(pred)
        except Exception as e:
            print(f"Error predicting for {req.tinh_thanh}: {e}")
    return results


@app.post("/train")
def train_model():
    """
    Train ML model t·ª´ historical data
    """
    try:
        success = train_ml_model()
        if success:
            return {"message": "Models trained successfully", "status": "success"}
        else:
            return {
                "message": "Not enough data to train models",
                "status": "insufficient_data"
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/predict/provinces")
def get_provinces():
    """
    L·∫•y danh s√°ch t·ªânh th√†nh c√≥ trong database
    """
    conn = get_db_connection()
    if not conn:
        return {"provinces": []}
    
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT DISTINCT 
                CASE 
                    WHEN dia_chi LIKE '%H√† N·ªôi%' THEN 'H√† N·ªôi'
                    WHEN dia_chi LIKE '%H·ªì Ch√≠ Minh%' OR dia_chi LIKE '%TP.HCM%' THEN 'H·ªì Ch√≠ Minh'
                    WHEN dia_chi LIKE '%ƒê√† N·∫µng%' THEN 'ƒê√† N·∫µng'
                    WHEN dia_chi LIKE '%H·∫£i Ph√≤ng%' THEN 'H·∫£i Ph√≤ng'
                    WHEN dia_chi LIKE '%C·∫ßn Th∆°%' THEN 'C·∫ßn Th∆°'
                    ELSE 'Kh√°c'
                END as province
            FROM yeu_cau_cuu_tros
            WHERE dia_chi IS NOT NULL
            LIMIT 20
        """)
        
        provinces = [row[0] for row in cursor.fetchall() if row[0]]
        cursor.close()
        conn.close()
        
        return {"provinces": list(set(provinces))}
    except Exception as e:
        if conn:
            conn.close()
        return {"provinces": []}


@app.get("/weather/check/{tinh_thanh}")
def check_weather(tinh_thanh: str):
    """
    Check th·ªùi ti·∫øt v√† d·ª± ƒëo√°n thi√™n tai cho m·ªôt t·ªânh th√†nh
    """
    if not check_weather_and_predict:
        raise HTTPException(
            status_code=503,
            detail="Weather service not available. Please install weather_service module."
        )
    
    try:
        result = check_weather_and_predict(tinh_thanh)
        
        # N·∫øu c√≥ nguy c∆° cao, t·ª± ƒë·ªông g·ª≠i c·∫£nh b√°o
        disaster_risk = result.get("disaster_risk", {})
        risk_level = disaster_risk.get("risk_level", "low")
        disaster_types = disaster_risk.get("disaster_types", [])
        
        if risk_level in ["high", "critical"] and disaster_types:
            send_alert_to_nextjs(
                tinh_thanh,
                disaster_types,
                risk_level,
                disaster_risk.get("details", {})
            )
        
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/weather/check-batch")
def check_weather_batch(provinces: List[str]):
    """
    Check th·ªùi ti·∫øt cho nhi·ªÅu t·ªânh th√†nh c√πng l√∫c
    """
    if not check_weather_and_predict:
        raise HTTPException(
            status_code=503,
            detail="Weather service not available"
        )
    
    results = []
    alerts_sent = []
    
    for province in provinces:
        try:
            result = check_weather_and_predict(province)
            results.append(result)
            
            # Check if alert needed
            disaster_risk = result.get("disaster_risk", {})
            risk_level = disaster_risk.get("risk_level", "low")
            disaster_types = disaster_risk.get("disaster_types", [])
            
            if risk_level in ["high", "critical"] and disaster_types:
                alert_sent = send_alert_to_nextjs(
                    province,
                    disaster_types,
                    risk_level,
                    disaster_risk.get("details", {})
                )
                if alert_sent:
                    alerts_sent.append(province)
        except Exception as e:
            print(f"Error checking weather for {province}: {e}")
            results.append({
                "tinh_thanh": province,
                "error": str(e)
            })
    
    return {
        "results": results,
        "alerts_sent": alerts_sent,
        "timestamp": datetime.now().isoformat()
    }


@app.post("/weather/alert")
def create_weather_alert(request: WeatherAlertRequest):
    """
    T·∫°o c·∫£nh b√°o th·ªùi ti·∫øt th·ªß c√¥ng
    """
    if not check_weather_and_predict:
        raise HTTPException(
            status_code=503,
            detail="Weather service not available"
        )
    
    try:
        result = check_weather_and_predict(request.tinh_thanh)
        disaster_risk = result.get("disaster_risk", {})
        
        # Force send alert
        disaster_types = disaster_risk.get("disaster_types", ["Thi√™n tai"])
        risk_level = disaster_risk.get("risk_level", "medium")
        
        message = request.message or f"C·∫£nh b√°o th·ªùi ti·∫øt cho {request.tinh_thanh}"
        
        send_alert_to_nextjs(
            request.tinh_thanh,
            disaster_types,
            risk_level,
            disaster_risk.get("details", {})
        )
        
        return {
            "message": "Alert sent successfully",
            "tinh_thanh": request.tinh_thanh,
            "disaster_risk": disaster_risk
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def periodic_weather_check():
    """
    H√†m ƒë∆∞·ª£c g·ªçi ƒë·ªãnh k·ª≥ ƒë·ªÉ check th·ªùi ti·∫øt cho c√°c t·ªânh th√†nh ch√≠nh
    """
    if not check_weather_and_predict:
        print("‚ö†Ô∏è  Weather service not available for periodic check")
        return
    
    # Danh s√°ch t·ªânh th√†nh c·∫ßn monitor
    provinces_to_check = [
        "H√† N·ªôi",
        "H·ªì Ch√≠ Minh",
        "ƒê√† N·∫µng",
        "H·∫£i Ph√≤ng",
        "C·∫ßn Th∆°",
        "Qu·∫£ng Ninh",
        "Th·ª´a Thi√™n Hu·∫ø",
        "Ngh·ªá An",
        "Thanh H√≥a",
        "B√¨nh ƒê·ªãnh"
    ]
    
    print(f"üîÑ Starting periodic weather check for {len(provinces_to_check)} provinces...")
    
    for province in provinces_to_check:
        try:
            result = check_weather_and_predict(province)
            disaster_risk = result.get("disaster_risk", {})
            risk_level = disaster_risk.get("risk_level", "low")
            disaster_types = disaster_risk.get("disaster_types", [])
            
            if risk_level in ["high", "critical"] and disaster_types:
                print(f"üö® ALERT: {province} - {', '.join(disaster_types)} - Risk: {risk_level}")
                send_alert_to_nextjs(
                    province,
                    disaster_types,
                    risk_level,
                    disaster_risk.get("details", {})
                )
            else:
                print(f"‚úÖ {province}: Risk level {risk_level}")
        except Exception as e:
            print(f"‚ùå Error checking {province}: {e}")
    
    print("‚úÖ Periodic weather check completed")


# Schedule periodic weather checks (m·ªói 6 gi·ªù)
scheduler.add_job(
    periodic_weather_check,
    trigger=CronTrigger(hour="*/6"),  # Every 6 hours
    id="periodic_weather_check",
    name="Periodic Weather Check",
    replace_existing=True
)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

